<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: elasticsearch | Adventures of a wannabe geek!]]></title>
  <link href="http://paulstack.co.uk/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://paulstack.co.uk/"/>
  <updated>2016-01-04T16:27:53+00:00</updated>
  <id>http://paulstack.co.uk/</id>
  <author>
    <name><![CDATA[Paul Stack (@stack72)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Building an ElasticSearch cluster in AWS with Packer and Terraform]]></title>
    <link href="http://paulstack.co.uk/blog/2016/01/02/building-an-elasticsearch-cluster-in-aws-with-packer-and-terraform/"/>
    <updated>2016-01-02T12:47:00+00:00</updated>
    <id>http://paulstack.co.uk/blog/2016/01/02/building-an-elasticsearch-cluster-in-aws-with-packer-and-terraform</id>
    <content type="html"><![CDATA[<p>As discussed in a <a href="http://www.paulstack.co.uk/blog/2015/11/09/the-quest-for-infra-management-2-dot-0/">previous post</a>, I like to build separate <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">AMIs</a> for each of my systems. This allows me to scale up and recycle nodes easily. I have been doing this with <a href="https://www.elastic.co/products/elasticsearch">ElasticSearch</a> for a while now. I usually build an AMI with <a href="https://packer.io/">Packer</a> and <a href="http://www.ansible.com/">Ansible</a> and I use <a href="https://terraform.io/">Terraform</a> to roll out the infrastructure</p>

<h3>Building ElasticSearch AMIs with Packer</h3>

<p>The packer template looks as follows:</p>

<p>
<code>json 
{
  &quot;variables&quot;: {
    &quot;ami_id&quot;: &quot;&quot;,
    &quot;private_subnet_id&quot;: &quot;&quot;,
    &quot;security_group_id&quot;: &quot;&quot;,
    &quot;packer_build_number&quot;: &quot;&quot;,
  },
  &quot;description&quot;: &quot;ElasticSearch Image&quot;,
  &quot;builders&quot;: [
    {
      &quot;ami_name&quot;: &quot;elasticsearch-{{user `packer_build_number`}}&quot;,
      &quot;availability_zone&quot;: &quot;eu-west-1a&quot;,
      &quot;iam_instance_profile&quot;: &quot;app-server&quot;,
      &quot;instance_type&quot;: &quot;t2.small&quot;,
      &quot;region&quot;: &quot;eu-west-1&quot;,
      &quot;run_tags&quot;: {
        &quot;role&quot;: &quot;packer&quot;
      },
      &quot;security_group_ids&quot;: [
        &quot;{{user `security_group_id`}}&quot;
      ],
      &quot;source_ami&quot;: &quot;{{user `ami_id`}}&quot;,
      &quot;ssh_timeout&quot;: &quot;10m&quot;,
      &quot;ssh_username&quot;: &quot;ubuntu&quot;,
      &quot;subnet_id&quot;: &quot;{{user `private_subnet_id`}}&quot;,
      &quot;tags&quot;: {
        &quot;Name&quot;: &quot;elasticsearch-packer-image&quot;
      },
      &quot;type&quot;: &quot;amazon-ebs&quot;
    }
  ],
  &quot;provisioners&quot;: [
    {
      &quot;type&quot;: &quot;shell&quot;,
      &quot;inline&quot;: [ &quot;sleep 10&quot; ]
    },
    {
      &quot;type&quot;: &quot;shell&quot;,
      &quot;script&quot;: &quot;install_dependencies.sh&quot;,
      &quot;execute_command&quot;: &quot;echo &#39;&#39; | {{ .Vars }} sudo -E -S sh &#39;{{ .Path }}&#39;&quot;
    },
    {
      &quot;type&quot;: &quot;ansible-local&quot;,
      &quot;playbook_file&quot;: &quot;elasticsearch.yml&quot;,
      &quot;extra_arguments&quot;: [
        &quot;--module-path=./modules&quot;
      ],
      &quot;playbook_dir&quot;: &quot;../../&quot;
    }
  ]
}
</code>
</p>

<p>This is essentially a pretty simple script and builds an AWS Instance in a private subnet of my choice in eu-west-1a in AWS. </p>

<h4>install_dependencies.sh</h4>

<p>The first part of the script just installs the dependencies that my system has:</p>

<p>
```bash</p>

<h1>!/bin/bash</h1>

<p>apt-get update
apt-get upgrade -y
apt-get install -y software-properties-common git
apt-add-repository -y ppa:ansible/ansible apt-get update</p>

<h1>workaround for ubuntu pip bug - https://bugs.launchpad.net/ubuntu/+source/python-pip/+bug/1306991</h1>

<p>rm -rf /usr/local/lib/python2.7/dist-packages/requests
apt-get install -y python-dev</p>

<p>ssh-keyscan -H github.com &gt; /etc/ssh/ssh<em>known</em>hosts</p>

<p>wget https://raw.github.com/pypa/pip/master/contrib/get-pip.py
python get-pip.py</p>

<p>pip install ansible paramiko PyYAML jinja2 httplib2 netifaces boto awscli six
```
</p>

<h4>Ansible playbook for ElasticSearch</h4>

<p>The ElasticSearch playbook looks as follows:</p>

<p>
```YAML<br>
- hosts: all
  sudo: yes</p>

<p>pre<em>tasks:
    - ec2</em>tags:
    - ec2_facts:</p>

<p>roles:
    - base
    - elasticsearch
```
</p>

<p>The playbook installs a base role for all the base pieces of my system (e.g. Logstash, Sensu-client, prometheus node_exporter) and then proceeds to install ElasticSearch. </p>

<p>The ElasticSearch role looks as follows:</p>

<p>
```YAML
- ec2<em>facts:
- ec2</em>tags:</p>

<ul>
<li><p>name: Add Oracle Java Repository
apt_repository: repo=&#39;ppa:webupd8team/java&#39;</p></li>
<li><p>name: Accept Java 8 Licence
shell: echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | tee /etc/oracle-java-8-licence-acceptance | /usr/bin/debconf-set-selections
args:
creates: /etc/oracle-java-8-licence-acceptance</p></li>
<li><p>name: Add ElasticSearch repo public signing key
apt_key: id=46095ACC8548582C1A2699A9D27D666CD88E42B4 url=https://packages.elastic.co/GPG-KEY-elasticsearch state=present</p></li>
<li><p>name: Add ElasticSearch repository
apt<em>repository:
repo: &#39;deb http://packages.elasticsearch.org/elasticsearch/{{ es</em>release }}/debian stable main&#39;
state: present</p></li>
<li><p>name: Install Oracle Java 8
apt: name={{item}} state=latest
with_items:</p>

<ul>
<li>oracle-java8-installer</li>
<li>ca-certificates</li>
<li>oracle-java8-set-default</li>
</ul></li>
<li><p>name: Install ElasticSearch
apt: name=elasticsearch={{ es_version }} state=present
notify: Restart elasticsearch</p></li>
<li><p>name: Copy /etc/default/elasticsearch
template: src=elasticsearch dest=/etc/default/elasticsearch
notify: Restart elasticsearch</p></li>
<li><p>name: Copy /etc/elasticsearch/elasticsearch.yml
template: src=elasticsearch.yml dest=/etc/elasticsearch/elasticsearch.yml
notify: Restart elasticsearch</p></li>
<li><p>name: Set elasticsearch service to start on boot
service: name=elasticsearch enabled=yes</p></li>
<li><p>name: Install plugins
command: bin/plugin --install {{item.name}}
args:
chdir: &quot;{{ es<em>home }}&quot;
creates: &quot;{{ es</em>home }}/plugins/{{ item.plugin<em>file | default(item.name.split(&#39;/&#39;)[1]) }}&quot;
with</em>items: es_plugins
notify: Restart elasticsearch</p></li>
<li><p>name: Set elasticsearch to be running
service: name=elasticsearch state=running enabled=yes</p></li>
</ul>
<div class="highlight"><pre><code class="text">

This is just some basic ansible commands to get the apt-repo, packages and plugins installed in the system. You can find the templates used [here](https://gist.github.com/stack72/bdef4126ae8b08214bd8). The important part to note is that variables are used both in the script **and** in the templates to setup the cluster to the required level.

My variables look as follows:
</code></pre></div>
<p>es<em>release: &quot;1.6&quot;
es</em>version: &quot;.0&quot;
es</em>home: /usr/share/elasticsearch
es<em>wait</em>for<em>listen: yes
es</em>etc:
  cluster<em>name: central</em>logging<em>cluster
  discovery.type: ec2
  discovery.ec2.groups: elasticsearch-sg
  cloud.aws.region: &quot;&quot;
es<em>default</em>es<em>heap</em>size: 4g
es<em>plugins:
  - name: elasticsearch/elasticsearch-cloud-aws/2.6.0
  - name: elasticsearch/marvel/latest
  - name: mobz/elasticsearch-head
es</em>etc<em>index</em>number<em>of</em>replicas: 2
```</p>

<p>As I have specified <code>elasticsearch-sg</code> and installed the <code>elasticsearch-cloud-aws</code> plugin, my nodes can auto-discover each other in the aws region. I can build the packer image as follows:</p>
<div class="highlight"><pre><code class="text">#!/bin/bash

LATEST_UBUNTU_IMAGE=$(curl http://cloud-images.ubuntu.com/locator/ec2/releasesTable | grep eu-west-1 | grep trusty | grep amd64 | grep &quot;\&quot;hvm:ebs\&quot;&quot; | awk -F &quot;[&lt;&gt;]&quot; &#39;{print $3}&#39;)

packer build \
  -var ami_id=$LATEST_UBUNTU_IMAGE \
  -var security_group_id=MYSGID\
  -var private_subnet_id=MYSUBNETID \
  -var packer_build_number=PACKERBUILDNUMBER \
  elasticsearch.json
</code></pre></div>
<p>We are now ready to build the infrastructure for the cluster</p>

<h3>Building an ElasticSearch Cluster with Terraform</h3>

<p>The infrastructure of the ElasticSearch cluster is now pretty easy. I deploy my nodes into a <a href="https://aws.amazon.com/vpc/">VPC</a> and onto private subnets so that they are not externally accessible. I have an <a href="https://aws.amazon.com/elasticloadbalancing/">ELB</a> in place across the nodes so that I can easily get to the ElasticSearch plugins like <a href="https://www.elastic.co/guide/en/marvel/current/index.html">Marvel</a> and <a href="https://mobz.github.io/elasticsearch-head/">Head</a>.</p>

<p>The Terraform configuration is as follows:  </p>
<div class="highlight"><pre><code class="text">resource &quot;aws_security_group&quot; &quot;elasticsearch&quot; {
  name = &quot;elasticsearch-sg&quot;
  description = &quot;ElasticSearch Security Group&quot;
  vpc_id = &quot;${aws_vpc.default.id}&quot;

  ingress {
    from_port = 9200
    to_port   = 9400
    protocol  = &quot;tcp&quot;
    security_groups = [&quot;${aws_security_group.elasticsearch_elb.id}&quot;]
  }

  ingress {
    from_port = 9200
    to_port   = 9400
    protocol  = &quot;tcp&quot;
    security_groups = [&quot;${aws_security_group.node.id}&quot;]
  }

  egress {
    from_port = &quot;0&quot;
    to_port = &quot;0&quot;
    protocol = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }

  tags {
    Name = &quot;ElasticSearch Node&quot;
  }
}


resource &quot;aws_security_group&quot; &quot;elasticsearch_elb&quot; {
  name = &quot;elasticsearch-elb-sg&quot;
  description = &quot;ElasticSearch Elastic Load Balancer Security Group&quot;
  vpc_id = &quot;${aws_vpc.default.id}&quot;

  ingress {
    from_port = 9200
    to_port   = 9200
    protocol  = &quot;tcp&quot;
    security_groups = [&quot;${aws_security_group.node.id}&quot;]
  }

  egress {
    from_port = &quot;0&quot;
    to_port = &quot;0&quot;
    protocol = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }

  tags {
    Name = &quot;ElasticSearch Load Balancer&quot;
  }
}

resource &quot;aws_elb&quot; &quot;elasticsearch_elb&quot; {
  name = &quot;elasticsearch-elb&quot;
  subnets = [&quot;${aws_subnet.primary-private.id}&quot;,&quot;${aws_subnet.secondary-private.id}&quot;,&quot;${aws_subnet.tertiary-private.id}&quot;]
  security_groups = [&quot;${aws_security_group.elasticsearch_elb.id}&quot;]
  cross_zone_load_balancing = true
  connection_draining = true
  internal = true

  listener {
    instance_port      = 9200
    instance_protocol  = &quot;tcp&quot;
    lb_port            = 9200
    lb_protocol        = &quot;tcp&quot;
  }

  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    interval            = 10
    target              = &quot;TCP:9200&quot;
    timeout             = 5
  }
}

resource &quot;aws_autoscaling_group&quot; &quot;elasticsearch_autoscale_group&quot; {
  name = &quot;elasticsearch-autoscale-group&quot;
  availability_zones = [&quot;${aws_subnet.primary-private.availability_zone}&quot;,&quot;${aws_subnet.secondary-private.availability_zone}&quot;,&quot;${aws_subnet.tertiary-private.availability_zone}&quot;]
  vpc_zone_identifier = [&quot;${aws_subnet.primary-private.id}&quot;,&quot;${aws_subnet.secondary-private.id}&quot;,&quot;${aws_subnet.tertiary-private.id}&quot;]
  launch_configuration = &quot;${aws_launch_configuration.elasticsearch_launch_config.id}&quot;
  min_size = 3
  max_size = 100
  desired = 3
  health_check_grace_period = &quot;900&quot;
  health_check_type = &quot;EC2&quot;
  load_balancers = [&quot;${aws_elb.elasticsearch_elb.name}&quot;]

  tag {
    key = &quot;Name&quot;
    value = &quot;elasticsearch&quot;
    propagate_at_launch = true
  }

  tag {
    key = &quot;role&quot;
    value = &quot;elasticsearch&quot;
    propagate_at_launch = true
  }

  tag {
    key = &quot;elb_name&quot;
    value = &quot;${aws_elb.elasticsearch_elb.name}&quot;
    propagate_at_launch = true
  }

  tag {
    key = &quot;elb_region&quot;
    value = &quot;${var.aws_region}&quot;
    propagate_at_launch = true
  }
}

resource &quot;aws_launch_configuration&quot; &quot;elasticsearch_launch_config&quot; {
  image_id = &quot;${var.elasticsearch_ami_id}&quot;
  instance_type = &quot;${var.elasticsearch_instance_type}&quot;
  iam_instance_profile = &quot;app-server&quot;
  key_name = &quot;${aws_key_pair.terraform.key_name}&quot;
  security_groups = [&quot;${aws_security_group.elasticsearch.id}&quot;,&quot;${aws_security_group.node.id}&quot;]
  enable_monitoring = false

  lifecycle {
    create_before_destroy = true
  }

  root_block_device {
    volume_size = &quot;${var.elasticsearch_volume_size}&quot;
  }
}
</code></pre></div>
<p>This allows me to scale my system up or down just by changing the values in my Terraform configuration. When the instances are instantiatied, the ElasticSearch cloud plugin discovers the other members of the cluster and allows the node to join the cluster</p>
]]></content>
  </entry>
  
</feed>
